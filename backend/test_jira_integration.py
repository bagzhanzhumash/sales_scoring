#!/usr/bin/env python3
"""
Test script for Jira integration functionality.
"""

import asyncio
import json
import pytest
from datetime import datetime
from unittest.mock import AsyncMock, patch

from app.jira_service import JiraService, JiraConfig, JiraTicketRequest
from app.models import (
    CallSummarizationResponse, 
    CallSummaryDetails, 
    SentimentDetails,
    ScorecardEntry
)


def create_test_call_summary() -> CallSummarizationResponse:
    """Create a test call summary for testing."""
    return CallSummarizationResponse(
        callSummary=CallSummaryDetails(
            category="–ü–µ—Ä–µ–≥–æ–≤–æ—Ä—ã",
            purpose="–ö–ª–∏–µ–Ω—Ç –æ–±—Å—É–∂–¥–∞–µ—Ç —É—Å–ª–æ–≤–∏—è –∏ —Å–ª–µ–¥—É—é—â–∏–π —à–∞–≥ –ø–æ —Å–¥–µ–ª–∫–µ",
            discussionPoints=[
                "–ö–ª–∏–µ–Ω—Ç: –ò–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è —Å–∫–ª–∞–¥–∞",
                "–ú–µ–Ω–µ–¥–∂–µ—Ä: –ü—Ä–µ–¥–ª–∞–≥–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ"
            ],
            actionItems=[
                "–ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
                "–†–∞—Å—Å—á–∏—Ç–∞—Ç—å —Å—Ç–æ–∏–º–æ—Å—Ç—å –ø—Ä–æ–µ–∫—Ç–∞"
            ],
            decisionMade="–ö–ª–∏–µ–Ω—Ç –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω, –∂–¥–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
            createdAt=datetime.now().strftime("%d.%m.%Y"),
            managerRecommendations=[
                "–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞: –ü–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ",
                "–û–±–Ω–æ–≤–∏—Ç–µ CRM, —á—Ç–æ–±—ã –∫–æ–º–∞–Ω–¥–∞ –≤–∏–¥–µ–ª–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å",
                "–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ next best action: –Ω–∞–∑–Ω–∞—á—å—Ç–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π –∑–≤–æ–Ω–æ–∫"
            ]
        ),
        sentiment=SentimentDetails(
            overall="–ü–æ–∑–∏—Ç–∏–≤–Ω–æ–µ",
            tone=["–£–≤–µ—Ä–µ–Ω–Ω—ã–π", "–î—Ä—É–∂–µ–ª—é–±–Ω—ã–π"],
            drivers=[
                "–ö–ª–∏–µ–Ω—Ç –∞–∫—Ç–∏–≤–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º",
                "–ú–µ–Ω–µ–¥–∂–µ—Ä –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —á–µ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã"
            ],
            recommendations=[
                "–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç–µ –¥–æ–≥–æ–≤–æ—Ä—ë–Ω–Ω–æ—Å—Ç–∏ –ø–∏—Å—å–º–æ–º",
                "–ù–∞–∑–Ω–∞—á—å—Ç–µ –ø–æ–≤—Ç–æ—Ä–Ω—ã–π —Å–æ–∑–≤–æ–Ω"
            ]
        ),
        scorecards=[
            ScorecardEntry(
                title="–í—ã—è–≤–ª–µ–Ω–∏–µ –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π",
                score=4.5,
                target=5,
                description="–ú–µ–Ω–µ–¥–∂–µ—Ä —É—Å–ø–µ—à–Ω–æ –≤—ã—è–≤–∏–ª –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏"
            )
        ]
    )


async def test_jira_service_configuration():
    """Test Jira service configuration."""
    print("üß™ Testing Jira service configuration...")
    
    config = JiraConfig(
        base_url="https://test.atlassian.net",
        username="test@example.com",
        api_token="test-token",
        project_key="TEST"
    )
    
    service = JiraService(config)
    assert service.config.base_url == "https://test.atlassian.net"
    assert service.config.project_key == "TEST"
    print("   ‚úÖ Configuration test passed")


async def test_extract_recommendations():
    """Test extraction of recommendations from call summary."""
    print("üß™ Testing recommendation extraction...")
    
    config = JiraConfig(
        base_url="https://test.atlassian.net",
        username="test@example.com",
        api_token="test-token",
        project_key="TEST"
    )
    
    service = JiraService(config)
    call_summary = create_test_call_summary()
    
    ticket_requests = service._extract_recommendations_from_call_summary(
        call_summary, 
        client_name="Test Client"
    )
    
    # Should have 5 tickets: 3 manager recommendations + 2 action items
    assert len(ticket_requests) == 5
    
    # Check first ticket content
    first_ticket = ticket_requests[0]
    assert "–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —à–∞–≥–∞" in first_ticket.summary
    assert "Test Client" in first_ticket.description
    assert "call-analysis" in first_ticket.labels
    assert "client-test-client" in first_ticket.labels
    
    print(f"   ‚úÖ Extracted {len(ticket_requests)} ticket requests")
    for i, ticket in enumerate(ticket_requests):
        print(f"   üìã Ticket {i+1}: {ticket.summary[:60]}...")


async def test_ticket_creation_mock():
    """Test ticket creation with mocked HTTP calls."""
    print("üß™ Testing ticket creation (mocked)...")
    
    config = JiraConfig(
        base_url="https://test.atlassian.net",
        username="test@example.com",
        api_token="test-token",
        project_key="TEST"
    )
    
    service = JiraService(config)
    
    # Mock HTTP response
    mock_response = {
        "id": "12345",
        "key": "TEST-123",
        "self": "https://test.atlassian.net/rest/api/3/issue/12345"
    }
    
    with patch('aiohttp.ClientSession.post') as mock_post:
        # Setup mock response
        mock_context = AsyncMock()
        mock_context.__aenter__.return_value.status = 201
        mock_context.__aenter__.return_value.json = AsyncMock(return_value=mock_response)
        mock_post.return_value = mock_context
        
        ticket_request = JiraTicketRequest(
            summary="Test ticket",
            description="Test description",
            project_key="TEST"
        )
        
        result = await service.create_ticket(ticket_request)
        
        assert result.ticket_id == "12345"
        assert result.ticket_key == "TEST-123"
        assert "TEST-123" in result.ticket_url
        
        print(f"   ‚úÖ Mock ticket created: {result.ticket_key}")


async def test_full_workflow_mock():
    """Test the full workflow from call summary to tickets (mocked)."""
    print("üß™ Testing full workflow (mocked)...")
    
    config = JiraConfig(
        base_url="https://test.atlassian.net",
        username="test@example.com",
        api_token="test-token",
        project_key="TEST"
    )
    
    service = JiraService(config)
    call_summary = create_test_call_summary()
    
    # Mock HTTP responses for multiple tickets
    mock_responses = [
        {"id": f"1234{i}", "key": f"TEST-{123+i}"} 
        for i in range(5)
    ]
    
    with patch('aiohttp.ClientSession.post') as mock_post:
        # Setup mock to return different responses for each call
        mock_contexts = []
        for response in mock_responses:
            mock_context = AsyncMock()
            mock_context.__aenter__.return_value.status = 201
            mock_context.__aenter__.return_value.json = AsyncMock(return_value=response)
            mock_contexts.append(mock_context)
        
        mock_post.side_effect = mock_contexts
        
        results = await service.create_tickets_from_call_summary(
            call_summary,
            client_name="Test Client"
        )
        
        assert len(results) == 5
        print(f"   ‚úÖ Created {len(results)} tickets in full workflow")
        
        for result in results:
            print(f"   üìã {result.ticket_key}: {result.summary[:50]}...")


def test_priority_assignment():
    """Test priority assignment based on content and sentiment."""
    print("üß™ Testing priority assignment...")
    
    config = JiraConfig(
        base_url="https://test.atlassian.net",
        username="test@example.com",
        api_token="test-token",
        project_key="TEST"
    )
    
    service = JiraService(config)
    
    # Test negative sentiment -> high priority
    negative_summary = create_test_call_summary()
    negative_summary.sentiment.overall = "–ù–µ–≥–∞—Ç–∏–≤–Ω–æ–µ"
    
    tickets = service._extract_recommendations_from_call_summary(negative_summary)
    
    # Should have high priority due to negative sentiment
    high_priority_count = sum(1 for t in tickets if t.priority == "High")
    assert high_priority_count > 0
    
    print(f"   ‚úÖ Priority assignment working: {high_priority_count} high priority tickets")


async def run_all_tests():
    """Run all tests."""
    print("üöÄ Starting Jira Integration Tests")
    print("=" * 50)
    
    try:
        await test_jira_service_configuration()
        await test_extract_recommendations()
        await test_ticket_creation_mock()
        await test_full_workflow_mock()
        test_priority_assignment()
        
        print("\nüéâ All tests passed!")
        
    except Exception as e:
        print(f"\n‚ùå Test failed: {e}")
        raise


def print_integration_summary():
    """Print summary of what the integration provides."""
    print("\nüìã Jira Integration Summary")
    print("=" * 50)
    print("‚úÖ Features implemented:")
    print("   ‚Ä¢ Extract actionable recommendations from call summaries")
    print("   ‚Ä¢ Create Jira tickets automatically from recommendations")
    print("   ‚Ä¢ Smart priority assignment based on sentiment")
    print("   ‚Ä¢ Contextual ticket descriptions with call details")
    print("   ‚Ä¢ Batch ticket creation for multiple recommendations")
    print("   ‚Ä¢ Asynchronous ticket creation for better performance")
    print("   ‚Ä¢ Health checks for integration status")
    print("   ‚Ä¢ Proper error handling and logging")
    
    print("\nüîå API Endpoints:")
    print("   ‚Ä¢ GET  /api/v1/jira/health")
    print("   ‚Ä¢ POST /api/v1/jira/create-ticket")
    print("   ‚Ä¢ POST /api/v1/jira/create-tickets-from-summary")
    print("   ‚Ä¢ POST /api/v1/jira/create-tickets-from-summary-async")
    
    print("\n‚öôÔ∏è  Configuration required:")
    print("   ‚Ä¢ JIRA_ENABLED=true")
    print("   ‚Ä¢ JIRA_BASE_URL=https://your-domain.atlassian.net")
    print("   ‚Ä¢ JIRA_USERNAME=your-email@example.com")
    print("   ‚Ä¢ JIRA_API_TOKEN=your-api-token")
    print("   ‚Ä¢ JIRA_PROJECT_KEY=SALES")


if __name__ == "__main__":
    print("Running Jira integration tests...")
    asyncio.run(run_all_tests())
    print_integration_summary()
